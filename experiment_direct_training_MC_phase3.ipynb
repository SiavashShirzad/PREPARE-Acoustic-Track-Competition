{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"processed_30seconds.csv\")\n",
    "# Original DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(data)\n",
    "\n",
    "# Attempt the user's code (which triggers SettingWithCopyWarning and may not modify the original)\n",
    "try:\n",
    "    data[data['sex'].notna()]['sex'] = data[data['sex'].notna()]['sex'].apply(lambda x: 'm' if x.lower()[0] == 'm' else 'f')\n",
    "except:\n",
    "    pass  # Ignore any errors for demonstration\n",
    "\n",
    "\n",
    "\n",
    "# Correct way using .loc to ensure modification of the original DataFrame\n",
    "data.loc[data['sex'].notna(), 'sex'] = data.loc[data['sex'].notna(), 'sex'].apply(lambda x: 'm' if x.lower()[0] == 'm' else 'f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6365.,    0.,    0.,    0.,    0., 2873.,    0.,    0.,    0.,\n",
       "        2469.]),\n",
       " array([0. , 0.2, 0.4, 0.6, 0.8, 1. , 1.2, 1.4, 1.6, 1.8, 2. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(data['MCL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from transformers import AutoProcessor, AutoModel\n",
    "import torchaudio\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "import audiomentations\n",
    "\n",
    "# Step 1: Use the predefined data variable\n",
    "print(\"Step 1: Using the predefined data variable...\")\n",
    "df = data\n",
    "print(f\"Dataframe with {len(df)} entries.\")\n",
    "\n",
    "# Step 1.5: Pre-training visualization of important factors\n",
    "print(\"Step 1.5: Visualizing important factors pre-training...\")\n",
    "\n",
    "# Distribution plots\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.histplot(df['MCL'], kde=False)\n",
    "plt.title('MCL Distribution')\n",
    "plt.tight_layout()\n",
    "plt.savefig('pre_distributions.png')\n",
    "plt.close()\n",
    "print(\"Pre-training distributions saved as 'pre_distributions.png'.\")\n",
    "\n",
    "# Step 2: Prepare data splits\n",
    "print(\"Step 2: Preparing data splits...\")\n",
    "df_train_full = df[df['split'] == 'train'].reset_index(drop=True)\n",
    "df_test = df[df['split'] == 'test'].reset_index(drop=True)\n",
    "\n",
    "# Split train_full into train and val by ID\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, val_idx = next(gss.split(df_train_full, groups=df_train_full['ID']))\n",
    "df_train = df_train_full.iloc[train_idx].reset_index(drop=True)\n",
    "df_val = df_train_full.iloc[val_idx].reset_index(drop=True)\n",
    "print(f\"Train set: {len(df_train)} samples, Internal Val set: {len(df_val)} samples, Test set: {len(df_test)} samples.\")\n",
    "\n",
    "# Step 3: Define the Dataset class\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, df, processor, is_train=False):\n",
    "        self.df = df\n",
    "        self.processor = processor\n",
    "        self.min_length = 16000  # Minimum length: 1 second at 16kHz to be safe\n",
    "        self.is_train = is_train\n",
    "        self.aug = audiomentations.Compose([\n",
    "            audiomentations.AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
    "            audiomentations.Gain(min_gain_db=-6, max_gain_db=6, p=0.5),\n",
    "            audiomentations.PitchShift(min_semitones=-4, max_semitones=4, p=0.5),\n",
    "            audiomentations.TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),\n",
    "            audiomentations.Shift(min_shift=-0.5, max_shift=0.5, p=0.5),\n",
    "            audiomentations.PolarityInversion(p=0.5),\n",
    "            audiomentations.LowPassFilter(min_cutoff_freq=150, max_cutoff_freq=2000, p=0.5),\n",
    "            audiomentations.HighPassFilter(min_cutoff_freq=100, max_cutoff_freq=500, p=0.5),\n",
    "        ])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        audio_path = row['processed_path']\n",
    "        \n",
    "        # Load audio (handles wav/mp3)\n",
    "        waveform, sr = torchaudio.load(audio_path)\n",
    "        # Resample to 16kHz for wav2vec2\n",
    "        resampler = torchaudio.transforms.Resample(sr, 16000)\n",
    "        waveform = resampler(waveform)\n",
    "        # Convert to mono if stereo\n",
    "        waveform = waveform.mean(dim=0) if waveform.shape[0] > 1 else waveform.squeeze(0)\n",
    "        \n",
    "        # Clamp to [-1,1] in case of unnormalized audio\n",
    "        waveform = torch.clamp(waveform, -1.0, 1.0)\n",
    "        \n",
    "        if self.is_train:\n",
    "            # Apply audiomentations\n",
    "            waveform_np = waveform.numpy()\n",
    "            waveform_np = self.aug(waveform_np, sample_rate=16000)\n",
    "            waveform = torch.from_numpy(waveform_np)\n",
    "        \n",
    "        # Add small noise to avoid issues with silent audio\n",
    "        waveform += 1e-6 * torch.randn_like(waveform)\n",
    "        \n",
    "        # Pad short audio\n",
    "        if waveform.numel() < self.min_length:\n",
    "            padding = self.min_length - waveform.numel()\n",
    "            waveform = torch.nn.functional.pad(waveform, (0, padding))\n",
    "        \n",
    "        # Manual normalization with min std to prevent division by small numbers\n",
    "        mean = waveform.mean()\n",
    "        std = waveform.std()\n",
    "        std = max(std, 1e-5)\n",
    "        waveform = (waveform - mean) / std\n",
    "        \n",
    "        # Process audio without further normalization\n",
    "        inputs = self.processor(waveform, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
    "        \n",
    "        # Label (0,1,2)\n",
    "        label = torch.tensor(row['MCL'], dtype=torch.long)\n",
    "        \n",
    "        return inputs['input_values'].squeeze(0), label\n",
    "\n",
    "# Step 4: Define the Model (Transformer-based with Wav2Vec2 for multi-class classification)\n",
    "class MultiClassModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.audio_model = AutoModel.from_pretrained(\"facebook/wav2vec2-base\")\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(self.audio_model.config.hidden_size, 512),\n",
    "            nn.BatchNorm1d(512),  # BatchNorm to prevent overfitting\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),  # Increased dropout\n",
    "            nn.Linear(512, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 3)  # 3 classes\n",
    "        )\n",
    "        \n",
    "    def forward(self, input_values):\n",
    "        # Extract audio features (mean pool over sequence)\n",
    "        audio_feats = self.audio_model(input_values).last_hidden_state.mean(dim=1)\n",
    "        return self.head(audio_feats)\n",
    "\n",
    "# Step 5: Setup processor, datasets, dataloaders\n",
    "print(\"Step 5: Setting up processor, datasets, and dataloaders...\")\n",
    "processor = AutoProcessor.from_pretrained(\"facebook/wav2vec2-base\")\n",
    "processor.feature_extractor.do_normalize = False  # We handle normalization manually\n",
    "train_dataset = AudioDataset(df_train, processor, is_train=True)\n",
    "val_dataset = AudioDataset(df_val, processor)\n",
    "test_dataset = AudioDataset(df_test, processor)\n",
    "\n",
    "# Dataloaders with reduced workers to prevent RAM overload\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=8, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=8, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=8, pin_memory=True)\n",
    "print(\"Datasets and dataloaders ready.\")\n",
    "\n",
    "# Step 6: Setup model, optimizer, loss, device\n",
    "print(\"Step 6: Setting up model, optimizer, and loss...\")\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = MultiClassModel().to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5, weight_decay=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()  # Cross Entropy for multi-class\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "print(f\"Model setup on {device}.\")\n",
    "\n",
    "# Step 7: Training loop (internal validation)\n",
    "num_epochs = 20\n",
    "print(\"Step 7: Starting training...\")\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "    \n",
    "    # Train\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    num_batches = 0\n",
    "    with tqdm(total=len(train_loader), desc=\"Training\") as pbar:\n",
    "        for batch in train_loader:\n",
    "            input_values, labels = batch[0].to(device), batch[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_values)\n",
    "            if torch.any(torch.isnan(outputs)):\n",
    "                print(\"NaN in outputs detected in training batch. Skipping...\")\n",
    "                continue\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            if torch.isnan(loss):\n",
    "                print(\"NaN loss detected in training batch. Skipping...\")\n",
    "                continue\n",
    "            loss.backward()\n",
    "            clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix({'Batch Loss': loss.item()})\n",
    "    \n",
    "    if num_batches > 0:\n",
    "        avg_train_loss = train_loss / num_batches\n",
    "        print(f\"Average Train Loss: {avg_train_loss:.4f}\")\n",
    "    else:\n",
    "        print(\"All training batches had NaN loss.\")\n",
    "    \n",
    "    # Internal Validate\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    num_val_batches = 0\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "    with torch.no_grad():\n",
    "        with tqdm(total=len(val_loader), desc=\"Internal Validation\") as pbar:\n",
    "            for batch in val_loader:\n",
    "                input_values, labels = batch[0].to(device), batch[1].to(device)\n",
    "                outputs = model(input_values)\n",
    "                if torch.any(torch.isnan(outputs)):\n",
    "                    print(\"NaN in outputs detected in validation batch. Skipping...\")\n",
    "                    continue\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                if torch.isnan(loss):\n",
    "                    print(\"NaN loss detected in validation batch. Skipping...\")\n",
    "                    continue\n",
    "                val_loss += loss.item()\n",
    "                num_val_batches += 1\n",
    "                val_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix({'Batch Loss': loss.item()})\n",
    "    \n",
    "    if num_val_batches > 0:\n",
    "        avg_val_loss = val_loss / num_val_batches\n",
    "        print(f\"Average Val Loss: {avg_val_loss:.4f}\")\n",
    "        \n",
    "        # Compute classification metrics per class\n",
    "        report = classification_report(val_labels, val_preds, digits=4)\n",
    "        print(\"Val Classification Report:\\n\", report)\n",
    "        \n",
    "        scheduler.step(avg_val_loss)\n",
    "    else:\n",
    "        print(\"All validation batches had NaN loss.\")\n",
    "    \n",
    "\n",
    "# Step 8: Final external validation on test set\n",
    "print(\"Step 8: Performing final external validation on test set...\")\n",
    "# Load best model\n",
    "model.load_state_dict(torch.load('best_multi_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0.0\n",
    "num_test_batches = 0\n",
    "test_preds = []\n",
    "test_labels = []\n",
    "with torch.no_grad():\n",
    "    with tqdm(total=len(test_loader), desc=\"Test\") as pbar:\n",
    "        for batch in test_loader:\n",
    "            input_values, labels = batch[0].to(device), batch[1].to(device)\n",
    "            outputs = model(input_values)\n",
    "            if torch.any(torch.isnan(outputs)):\n",
    "                print(\"NaN in outputs detected in test batch. Skipping...\")\n",
    "                continue\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            if torch.isnan(loss):\n",
    "                print(\"NaN loss detected in test batch. Skipping...\")\n",
    "                continue\n",
    "            test_loss += loss.item()\n",
    "            num_test_batches += 1\n",
    "            test_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
    "            test_labels.extend(labels.cpu().numpy())\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix({'Batch Loss': loss.item()})\n",
    "\n",
    "if num_test_batches > 0:\n",
    "    avg_test_loss = test_loss / num_test_batches\n",
    "    print(f\"Average Test Loss: {avg_test_loss:.4f}\")\n",
    "    \n",
    "    # Compute classification metrics per class\n",
    "    report = classification_report(test_labels, test_preds, digits=4)\n",
    "    print(\"Test Classification Report:\\n\", report)\n",
    "\n",
    "# Step 9: Post-training visualization\n",
    "print(\"Step 9: Visualizing post-training factors...\")\n",
    "# Confusion matrix for test\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Test Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.savefig('test_confusion_matrix.png')\n",
    "plt.close()\n",
    "print(\"Test confusion matrix saved as 'test_confusion_matrix.png'.\")\n",
    "\n",
    "# Simple feature importance via permutation on test (only audio now)\n",
    "# Baseline CE loss\n",
    "baseline_loss = avg_test_loss  # Use CE\n",
    "\n",
    "# Permute audio\n",
    "test_preds_audio_perm = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_values, labels = batch[0].to(device), batch[1].to(device)\n",
    "        input_values = input_values[torch.randperm(input_values.size(0))]\n",
    "        outputs = model(input_values)\n",
    "        test_preds_audio_perm.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
    "# Compute permuted loss\n",
    "outputs_perm = torch.zeros((len(test_preds_audio_perm), 3)).to(device)\n",
    "outputs_perm[range(len(test_preds_audio_perm)), test_preds_audio_perm] = 1.0  # One-hot for loss calc\n",
    "labels_tensor = torch.tensor(test_labels).to(device)\n",
    "test_loss_audio_perm = nn.CrossEntropyLoss()(outputs_perm, labels_tensor).item()\n",
    "importance_audio = test_loss_audio_perm - baseline_loss\n",
    "print(f\"Importance of Audio: {importance_audio:.4f}\")\n",
    "\n",
    "# Bar plot for importances\n",
    "importances = {'Audio': importance_audio}\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(importances.keys(), importances.values())\n",
    "plt.title('Post-training Feature Importances (Permutation on Test)')\n",
    "plt.ylabel('Increase in CE Loss')\n",
    "plt.savefig('post_feature_importances.png')\n",
    "plt.close()\n",
    "print(\"Post-training feature importances saved as 'post_feature_importances.png'.\")\n",
    "\n",
    "# Step 10: Finalize\n",
    "print(\"Step 10: Training and evaluation completed. Best model saved as 'best_multi_model.pth'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
